>本文为《吴恩达机器学习》的要点记录

# 推荐系统 Recommender Systems

**对机器学习来说，特征是很重要的，你所选择的特征，将对你学习算法的性能有很大的影响。因此，在机器学习中有一种大思想，它针对一些问题，可能并不是所有的问题，而是一些问题，有算法可以为你自动学习一套好的特征。**

有一些设置，你可以有一个算法，仅仅学习其使用的特征，推荐系统就是类型设置的一个例子。让我们从一个例子开始定义推荐系统的问题:

假使我们是一个电影供应商，我们有 5 部电影和 4 个用户，我们要求用户为电影打分。

![pic](pic/reommendSys1.png)

前三部电影是爱情片，后两部则是动作片，我们可以看出Alice和Bob似乎更倾向与爱情片， 而 Carol 和 Dave 似乎更倾向与动作片。并且没有一个用户给所有的电影都打过分。我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分，并以此作为推荐的依据。

下面引入一些标记：

$n_{u}$代表用户的数量

$n_{m}$代表电影的数量

$r_{(i,j)}$代表如果用户j给电影i评过分则$r_{(i,j)}=1$
 
$y^{(i,j)}$代表用户j给电影i的评分

$m_{j}$代表用户$j$评过分的电影的总数

## 基于内容的推荐系统

在一个基于内容的推荐系统算法中，我们希望基于已有的内容的特征来推荐一些数据。

在我们的例子中，我们可以假设每部电影都有两个特征，如$x_{1}$代表电影的浪漫程度，$x_{2}$代表电影的动作程度。

![pic](pic/reommendSys2.png)

则每部电影都有一个特征向量，如$x^{(1)}$是第一部电影的特征向量为[0.9 0]。

我们要基于这些特征来构建一个推荐系统算法。 假设我们采用线性回归模型，我们可以针对每一个用户都训练一个线性回归模型，如$\theta^{(1)}$是第一个用户的模型的参数。于是我们有:

$\theta^{(j)}$是用户$j$的参数向量

$x^{(i)}$是电影$i$的特征向量

对于用户$j$和电影$i$，我们预测评分为:$(\theta^{(j)})^{T}x^{(i)}$

针对用户$j$，它的线性回归模型的代价为预测误差的平方和，加上正则化项:

$$
\min_{\theta^{(j)}}\frac{1}{2}\sum_{i:r(i,j)=1}((\theta^{(j)})^{T}x^{(i)}- y^{(i,j)})^{2}+\frac{\lambda}{2}(\theta_{k}^{(j)})^{2}
$$

其中$i:r(i,j)=1$表示我们只计算那些用户$j$评过分的电影。

上面的代价函数只是针对一个用户的，为了学习所有用户，我们将所有用户的代价函数求和:

$$
\min_{\theta^{(1),...\theta^{n_u}}}\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}((\theta^{(j)})^{T}x^{(i)}- y^{(i,j)})^{2}+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_{k}^{(j)})^{2}
$$

在基于内容的推荐系统中，对于每一部电影，我们都掌握了可用的特征，使用这些特征训练出了每一个用户的参数。相反地，如果我们拥有用户的参数，我们可以学习得出电影的特征。

**协同过滤算法可以同时学习这两者。**

我们的优化目标便改为同时针对$x$和$\theta$进行:

$$
J(x^{(1)},...x^{(n)}, \theta^{(1)},...\theta^{(n_u)})=\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}((\theta^{(j)})^{T}x^{(i)}- y^{(i,j)})^{2}+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_{k}^{(j)})^{2}+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_{k}^{(j)})^{2}
$$

对上面代价函数求偏导数如下:

$$
x_{k}^{(i)} := x_{k}^{(i)}-\alpha(\sum_{i:r(i,j)=1}((\theta^{(j)})^{T}x^{(i)}- y^{(i,j)}\theta_{k}^{i}) + \lambda x_{k}^{(i)})
$$

$$
\theta_{k}^{(i)} := \theta_{k}^{(i)}-\alpha(\sum_{i:r(i,j)=1}((\theta^{(j)})^{T}x^{(i)}- y^{(i,j)}x_{k}^{i}) + \lambda \theta_{k}^{(i)})
$$

协同过滤算法的使用步骤如下:

1. 初始 $x^{(1)},...x^{(n)}, \theta^{(1)},...\theta^{(n_u)}$为一些随机小值
2. 使用梯度下降算法最小化代价函数
3. 在训练完算法后，我们预测$(\theta^{(j)})^{T}x^{(i)}$为用户j$$给电影$i$的评分

通过这个学习过程获得的特征矩阵包含了有关电影的重要数据，这些数据不总是人能读懂的，但是我们可以用这些数据作为给用户推荐电影的依据。

例如，如果一位用户正在观看电影$x^{(i)}$，我们可以寻找另一部电影$x^{(j)}$，依据两部电影的特征向量之间的距离$\lVert x^{(i)}-x^{(j)} \lVert$的大小。