
简单回顾一下非监督学习: 在非监督学习中，我们需要将一系列无标签（$y$）的训练数据，输入到一个算法中，然后我们告诉这个算法，快去为我们找找这个数据的内在结构给定数据。

# 聚类 Clustering  (非监督学习算法)

聚类算法简单的说就是把数据在训练集中分成不同的簇。

## K-均值算法

它是最普及的聚类算法，算法接受一个未标记的数据集，然后将数据聚类成不同的组。

它的算法为:

1. 首先选择$K$个随机的点，称为聚类中心（cluster centroids）
2. 对于数据集中的每一个数据，按照距离$K$个中心点的距离，将其与距离最近的中心点关联起来，与同一个中心点关联的所有点聚成一类。
3. 计算每一个组的平均值，将该组所关联的中心点移动到平均值的位置。
4. 重复步骤2-3直至中心点不再变化。

用$\mu^{1},\mu^{2},...\mu^{n}$来表示聚类中心，用$c^{(1)},c^{(2)},...c^{(m)}$来存储与第$i$个实例数据最近的聚类中心的索引，K-均值算法的伪代码如下：

```
 
Repeat {
​
    for i = 1 to m
​
        c(i) := index (form 1 to K) of cluster centroid closest to x(i)
​
    for k = 1 to K
​
        μk := average (mean) of points assigned to cluster k

}
```

算法分为两个步骤，第一个**for**循环是赋值步骤，即：对于每一个样例$i$，计算其应该属于的类。第二个**for**循环是聚类中心的移动，即：对于每一个类$K$，重新计算该类的质心。